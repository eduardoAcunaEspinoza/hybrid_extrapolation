# --- Experiment configurations --------------------------------------------------------------------

# experiment name, used as folder name
experiment_name: hybrid_extrapolation_seed_444444

# place to store run directory (if empty runs are stored in $cwd$/runs/)
run_dir: 

# files to specify training, validation and test basins (relative to code root or absolute path)
train_basin_file: ../data/basin_id/basins_camels_us_531.txt
validation_basin_file: ../data/basin_id/basins_camels_us_531.txt
test_basin_file: ../data/basin_id/basins_camels_us_531.txt

# training, validation and test time periods (format = 'dd/mm/yyyy')
per_basin_train_periods_file: ../data/CAMELS_US/train_split_file_new.p
test_start_date: '31/12/1980'
test_end_date: '30/09/2014'
validation_start_date: '01/10/1980'
validation_end_date: '30/09/1985'

# fixed seed, leave empty to use a random seed
seed: 444444

# which GPU (id) to use [in format of cuda:0, cuda:1 etc, or cpu or None]
device: cuda:0

# --- Validation configuration ---------------------------------------------------------------------

# specify after how many epochs to perform validation
validate_every: 20

# specify how many random basins to use for validation
validate_n_random_basins: 50

# specify which metrics to calculate during validation (see codebase.evaluation.metrics)
metrics:
- NSE

# --- Model configuration --------------------------------------------------------------------------

# base model type
model: hybrid_model

# conceptual part of the hybrid model
conceptual_model: HBV

# routing method
conceptual_routing: True

# define parameterization type of conceptual model
conceptual_model_dynamic_parameterization:
- BETA
- BETAET

n_conceptual_models: 16

# prediction head [regression, mdn, umal]. Define the head specific parameters below
head: regression

# ----> General settings <----

# Number of cell states of the LSTM
hidden_size: 256

# Initial bias value of the forget gate
initial_forget_bias: 3

# Dropout applied to the output of the LSTM
output_dropout: 0.4

output_activation: linear

# --- Training configuration -----------------------------------------------------------------------

# specify optimizer [Adam, Adadelta]
optimizer: Adam

# specify loss [MSE, NSE, RMSE, UMALLoss, MDNLoss]
loss: weightedrmse

# specify learning rates to use starting at specific epochs (0 is the initial learning rate)
learning_rate:
    0: 1e-3
    10: 5e-4
    20: 1e-4

# Mini-batch size
batch_size: 256

# Number of training epochs
epochs: 20

# If True, clips norm of gradients
clip_gradient_norm: 1

# Defines which time steps are used to calculate the loss. Can't be larger than seq_length
predict_last_n: 365

# Length of the input sequence (365 warmup + 365 training)
seq_length: 730

# Maximum number of weight updates per training epoch
max_updates_per_epoch: 450

# Number of parallel workers used in the data pipeline
num_workers: 8

# Log the training loss every n steps
log_interval: 1

# If true, writes logging results into tensorboard file
log_tensorboard: True

# Save model weights every n epochs
save_weights_every: 1

# Store the results of the validation to disk
save_validation_results: True

# --- Data configurations --------------------------------------------------------------------------

dataset: camels_us

# Path to CAMELS data set
data_dir: ../data/CAMELS_US

# Forcing product [daymet, maurer, maurer_extended, nldas, nldas_extended]
# can be either a list of forcings or a single forcing product
forcings:
- daymet

# variables to use as time series input (names match the data file column headers)
# Note: In case of multiple input forcing products, you have to append the forcing product behind
# each variable. E.g. 'prcp(mm/day)' of the daymet product is 'prcp(mm/day)_daymet'
dynamic_inputs:
- prcp(mm/day)
- srad(W/m2)
- tmax(C)
- tmin(C)
- vp(Pa)
- dayl(s)

duplicate_features:
- prcp(mm/day)
- tmax(C)
- tmin(C)

dynamic_conceptual_inputs:
- prcp(mm/day)_copy1
- pet(mm/day)
- tmax(C)_copy1
- tmin(C)_copy1

# which columns to use as target
target_variables:
- QObs(mm/d)

static_attributes:
- p_mean
- pet_mean
- p_seasonality
- frac_snow
- aridity
- high_prec_freq
- high_prec_dur
- low_prec_freq
- low_prec_dur
- elev_mean
- slope_mean
- area_gages2
- frac_forest
- lai_max
- lai_diff
- gvf_max
- gvf_diff
- dom_land_cover_frac
- dom_land_cover
- root_depth_50
- soil_depth_pelletier
- soil_depth_statsgo
- soil_porosity
- soil_conductivity
- max_water_content
- sand_frac
- silt_frac
- clay_frac
- geol_1st_class
- glim_1st_class_frac
- geol_2nd_class
- glim_2nd_class_frac
- carbonate_rocks_frac
- geol_porostiy
- geol_permeability

# Path to additional_features (evapotranspiration)
additional_feature_files: ../data/CAMELS_US/pet_hargreaves.pickle

# Custom normalization
custom_normalization:
    QObs(mm/d):
        centering: None
        scaling: None
    prcp(mm/day)_copy1:
        centering: None
        scaling: None
    pet(mm/day):
        centering: None
        scaling: None
    tmax(C)_copy1:
        centering: None
        scaling: None
    tmin(C)_copy1:
        centering: None
        scaling: None
