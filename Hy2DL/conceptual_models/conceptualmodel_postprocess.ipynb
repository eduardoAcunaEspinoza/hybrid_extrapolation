{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from evaluation_metrics import nse_loss\n",
    "from hydrological_models import HBV\n",
    "from modelcalibration_camelsus import ModelCalibrationCamelsUS as model_calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize information\n",
    "path_data = \"../../data/CAMELS_US\"\n",
    "path_additional_features = \"../../data/CAMELS_US/pet_hargreaves.pickle\"\n",
    "path_output = \"../results/HBV_extrapolation/\"\n",
    "\n",
    "input_variables = [\"prcp(mm/day)\", \"pet(mm/day)\", \"tmax(C)\", \"tmin(C)\"]\n",
    "target_variables = [\"QObs(mm/d)\"]\n",
    "forcing = \"daymet\"\n",
    "warmup_period = 365\n",
    "\n",
    "testing_period = \"../../data/CAMELS_US/test_split_file_new.p\"\n",
    "hydrological_model = HBV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the calibration results by each method, and select the best case. In other words, select the calibrated\n",
    "# parameters (for each basin) that gave best results.\n",
    "\n",
    "# DREAM calibration\n",
    "df_dream = pd.read_csv(path_output + hydrological_model.name + '_dream_summary.csv', dtype={'basin_id': str})\n",
    "df_dream.set_index('basin_id', inplace=True)\n",
    "basins_id = df_dream.index\n",
    "\n",
    "# SCE calibration\n",
    "df_sce = pd.read_csv(path_output + hydrological_model.name + '_sce_summary.csv', dtype={'basin_id': str})\n",
    "df_sce.set_index('basin_id', inplace=True)\n",
    "\n",
    "# The fist column of each dataset is the NSE in training.\n",
    "nse_training = pd.concat([df_dream.iloc[:, 0], df_sce.iloc[:, 0]], axis=1,  keys=['dream', 'sce'])\n",
    "max_value_index = nse_training.idxmax(axis=1)\n",
    "\n",
    "# Select the best parameter set for each basin\n",
    "parameter_sets = pd.concat([df_dream[max_value_index=='dream'].iloc[:, 1:-1], \n",
    "                            df_sce[max_value_index=='sce'].iloc[:, 1:-1]], axis=0)\n",
    "parameter_sets= parameter_sets.reindex(df_dream.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model for each basin, using the best calibration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "NSE_testing =  []\n",
    "\n",
    "# Loop that goes through each basin\n",
    "for i, basin in enumerate(basins_id):\n",
    "    testing_object = model_calibration(model = hydrological_model, \n",
    "                                       path_data = path_data,\n",
    "                                       forcing=forcing,\n",
    "                                       basin_id = basin, \n",
    "                                       input_variables = input_variables, \n",
    "                                       target_variables = target_variables,\n",
    "                                       time_period = testing_period, \n",
    "                                       obj_func = None, \n",
    "                                       warmup_period = warmup_period,\n",
    "                                       path_additional_features=path_additional_features)\n",
    "    \n",
    "    # Testing period ------------------------------------------\n",
    "    q_sim = testing_object.simulation(parameter_sets.loc[basin].values)\n",
    "    q_obs = testing_object.evaluation()\n",
    "\n",
    "    # Calculate loss\n",
    "    evaluation = q_obs[warmup_period:][testing_object.data_split[warmup_period:]]\n",
    "    simulation = q_sim[warmup_period:][testing_object.data_split[warmup_period:]]\n",
    "\n",
    "    # Store information in dataframe\n",
    "    time_index = testing_object.timeseries['df'].index[warmup_period:][testing_object.data_split[warmup_period:]]\n",
    "    df_discharge = pd.DataFrame(data={'y_obs': evaluation, 'y_sim': simulation}, index=time_index)\n",
    "    test_results[basin] = df_discharge\n",
    "    \n",
    "    # Calculate NSE\n",
    "    mask_nans = ~np.isnan(evaluation)\n",
    "    NSE_testing.append(nse_loss(evaluation=evaluation[mask_nans].flatten(),\n",
    "                                 simulation=simulation[mask_nans].flatten()))\n",
    "\n",
    "# Save NSE values in csv\n",
    "df_NSE = pd.DataFrame(data={'basin_id': basins_id,'NSE': NSE_testing})\n",
    "df_NSE = df_NSE.set_index('basin_id')\n",
    "df_NSE.to_csv(path_output+'/'+hydrological_model.name+'_NSE.csv', index=True, header=True)\n",
    "\n",
    "# Save simulated values in pickle file\n",
    "with open(path_output+\"/HBV_results.pickle\", \"wb\") as f:\n",
    "    pickle.dump(test_results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "42b7dc197ee81dd2f6541889b0e14556b882d218c1e7c97db94bc0f7b191f034"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
